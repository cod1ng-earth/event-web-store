// Code generated by simba. DO NOT EDIT.

package checkout

import (
	"fmt"
	"log"
	"sync"

	"github.com/Shopify/sarama"
	"github.com/golang/protobuf/proto"

	pim "github.com/cod1ng-earth/event-web-store/backend/pkg/context/pim/public"

	fulfilment "github.com/cod1ng-earth/event-web-store/backend/pkg/context/fulfilment/public"

	public "github.com/cod1ng-earth/event-web-store/backend/pkg/context/checkout/public"
)

const (
	Topic     = "checkout_internal"
	Partition = 0
)

type context struct {
	doneCh chan struct{}

	doneChPim chan struct{}

	doneChFulfilment chan struct{}

	client   sarama.Client
	consumer sarama.Consumer

	publisherConsumer sarama.Consumer
	publisher         publisher

	internalTopic internalTopic

	aggregator aggregator
}

func NewContext(brokers *[]string, cfg *sarama.Config) context {

	client, err := sarama.NewClient(*brokers, cfg)
	if err != nil {
		log.Panicf("failed to setup kafka client: %s", err)
	}
	consumer, err := sarama.NewConsumerFromClient(client)
	if err != nil {
		log.Panicf("failed to setup kafka consumer: %s", err)
	}

	publisherConsumer, err := sarama.NewConsumerFromClient(client)
	if err != nil {
		log.Panicf("failed to setup kafka consumer for publisher: %s", err)
	}

	producer, err := sarama.NewSyncProducerFromClient(client)
	if err != nil {
		log.Panicf("failed to setup kafka producer: %s", err)
	}

	batchOffset, err := client.GetOffset(Topic, Partition, sarama.OffsetNewest)
	if err != nil {
		log.Printf("failed to get last offset for topic %v partition %v", Topic, Partition)
	}
	batchOffset--

	context := context{
		doneCh: make(chan struct{}, 1),

		doneChPim: make(chan struct{}, 1),

		doneChFulfilment: make(chan struct{}, 1),

		client:   client,
		consumer: consumer,

		publisherConsumer: publisherConsumer,

		internalTopic: internalTopic{
			producer: producer,
		},

		aggregator: aggregator{

			model: newModel(),
			lock:  &sync.RWMutex{},

			batchOffset:   batchOffset,
			offset:        0,
			offsetChanged: sync.NewCond(&sync.Mutex{}),
		},
	}
	return context
}

func (c *context) Stop() {
	c.doneCh <- struct{}{}
}

func (c *context) Start() {

	log.Printf("starting context %v", Topic)

	writes := make(chan *sarama.ConsumerMessage, 32768)
	go c.aggregator.updateLoop(writes)

	partition, err := c.consumer.ConsumePartition(Topic, 0, 0)
	if err != nil {
		log.Panicf("failed to setup kafka partition: %s", err)
	}

	publisherPartition, err := c.publisherConsumer.ConsumePartition(Topic, 0, 0)
	if err != nil {
		log.Panicf("failed to setup kafka partition for publisher: %s", err)
	}
	go c.publisher.updateLoop(publisherPartition.Messages())

	go c.bridgePim()

	go c.bridgeFulfilment()

	for {
		select {
		case err := <-partition.Errors():
			log.Printf("failure from kafka consumer: %s", err)

		case msg := <-partition.Messages():
			//			log.Printf("recieved message with offset %v", msg.Offset)
			writes <- msg

		case <-c.doneCh:
			log.Print("interrupt is detected")

			c.doneChPim <- struct{}{}

			c.doneChFulfilment <- struct{}{}

			if err := partition.Close(); err != nil {
				log.Panicf("failed to close kafka partition: %s", err)
			}
			close(writes)
			if err := c.consumer.Close(); err != nil {
				log.Panicf("failed to close kafka consumer: %s", err)
			}

			if err := publisherPartition.Close(); err != nil {
				log.Panicf("failed to close kafka partition for publisher: %s", err)
			}
			if err := c.publisherConsumer.Close(); err != nil {
				log.Panicf("failed to close kafka consumer for publisher: %s", err)
			}

			if err := c.internalTopic.producer.Close(); err != nil {
				log.Panicf("failed to close kafka producer: %s", err)
			}
			if err := c.client.Close(); err != nil {
				log.Panicf("failed to close kafka client: %s", err)
			}
			return
		}
	}
}

type aggregator struct {
	consumer    sarama.Consumer
	aggregation model

	model *model
	lock  *sync.RWMutex

	batchOffset   int64
	offset        int64
	offsetChanged *sync.Cond
}

func (c *aggregator) await(offset int64) {
	if offset == -1 {
		return
	}
	if c.offset >= offset {
		return
	}
	c.offsetChanged.L.Lock()
	for c.offset < offset {
		c.offsetChanged.Wait()
	}
	c.offsetChanged.L.Unlock()
}

func (c *aggregator) AwaitLastOffset() {
	// TODO wait for brides to be up to date
	c.await(c.batchOffset)
}

func (c *context) Healthy() bool {
	return c.aggregator.offset >= c.aggregator.batchOffset
}

func (c *aggregator) updateLoop(writes <-chan *sarama.ConsumerMessage) {

	for {

		for msg := range writes {
			c.applyChange(msg, c.model)
		}

	}
}

func (c *aggregator) applyChange(msg *sarama.ConsumerMessage, m *model) {

	//	log.Printf("applying message with offset %v", msg.Offset)

	c.lock.Lock()
	defer c.lock.Unlock()
	defer func() {
		c.offset = msg.Offset
		c.offsetChanged.Broadcast()
	}()

	c.updateModel(msg, m)
}

func (c aggregator) updateModel(msg *sarama.ConsumerMessage, model *model) error {
	cc := TopicMessage{}
	err := proto.Unmarshal(msg.Value, &cc)
	if err != nil {
		return fmt.Errorf("failed to unmarshal kafka massage %s/%d: %v", Topic, msg.Offset, err)
	}

	switch x := cc.GetMessages().(type) {

	case *TopicMessage_ChangeProductQuantity:
		fact := cc.GetChangeProductQuantity()
		err = updateModelChangeProductQuantity(model, msg.Offset, fact)
		if err != nil {
			return fmt.Errorf("failed to update kafka massage %s/%d: %v", Topic, msg.Offset, err)
		}

	case *TopicMessage_StockCorrected:
		fact := cc.GetStockCorrected()
		err = updateModelStockCorrected(model, msg.Offset, fact)
		if err != nil {
			return fmt.Errorf("failed to update kafka massage %s/%d: %v", Topic, msg.Offset, err)
		}

	case *TopicMessage_Product:
		fact := cc.GetProduct()
		err = updateModelProduct(model, msg.Offset, fact)
		if err != nil {
			return fmt.Errorf("failed to update kafka massage %s/%d: %v", Topic, msg.Offset, err)
		}

	case *TopicMessage_OrderCart:
		fact := cc.GetOrderCart()
		err = updateModelOrderCart(model, msg.Offset, fact)
		if err != nil {
			return fmt.Errorf("failed to update kafka massage %s/%d: %v", Topic, msg.Offset, err)
		}

	case nil:
		panic(fmt.Sprintf("context message is empty"))

	default:
		panic(fmt.Sprintf("unexpected type %T in oneof", x))
	}

	return nil
}

func (c *context) bridgePim() {

	c.aggregator.AwaitLastOffset()

	model, free := c.aggregator.read()
	pimOffset := model.getPimOffset()
	free()
	partition, err := c.consumer.ConsumePartition(pim.Topic, 0, pimOffset)
	if err != nil {
		log.Panicf("failed to setup kafka partition: %s", err)
	}

	log.Printf("starting bridge %v", Topic)

	for {
		select {
		case err := <-partition.Errors():
			log.Printf("failure from kafka consumer: %s", err)

		case msg := <-partition.Messages():
			//			log.Printf("recieved message with offset %v", msg.Offset)

			cc := pim.TopicMessage{}
			err := proto.Unmarshal(msg.Value, &cc)
			if err != nil {
				log.Fatalf("failed to unmarshal kafka massage %s/%d: %v", Topic, msg.Offset, err)
			}

			switch x := cc.GetMessages().(type) {

			case *pim.TopicMessage_Product:
				if err := translatePimProduct(c, model, msg.Offset, cc.GetProduct()); err != nil {
					log.Fatalf("failed to translate kafka message $bridge.Name/%v: %s", msg.Offset, err)
				}

			case nil:
				panic(fmt.Sprintf("context message is empty"))

			default:
				panic(fmt.Sprintf("unexpected type %T in oneof", x))
			}

		}
	}
}

func (c *context) bridgeFulfilment() {

	c.aggregator.AwaitLastOffset()

	model, free := c.aggregator.read()
	fulfilmentOffset := model.getFulfilmentOffset()
	free()
	partition, err := c.consumer.ConsumePartition(fulfilment.Topic, 0, fulfilmentOffset)
	if err != nil {
		log.Panicf("failed to setup kafka partition: %s", err)
	}

	log.Printf("starting bridge %v", Topic)

	for {
		select {
		case err := <-partition.Errors():
			log.Printf("failure from kafka consumer: %s", err)

		case msg := <-partition.Messages():
			//			log.Printf("recieved message with offset %v", msg.Offset)

			cc := fulfilment.TopicMessage{}
			err := proto.Unmarshal(msg.Value, &cc)
			if err != nil {
				log.Fatalf("failed to unmarshal kafka massage %s/%d: %v", Topic, msg.Offset, err)
			}

			switch x := cc.GetMessages().(type) {

			case *fulfilment.TopicMessage_StockCorrected:
				if err := translateFulfilmentStockCorrected(c, model, msg.Offset, cc.GetStockCorrected()); err != nil {
					log.Fatalf("failed to translate kafka message $bridge.Name/%v: %s", msg.Offset, err)
				}

			case nil:
				panic(fmt.Sprintf("context message is empty"))

			default:
				panic(fmt.Sprintf("unexpected type %T in oneof", x))
			}

		}
	}
}

func (c aggregator) read() (*model, func()) {

	c.offsetChanged.L.Lock()
	for c.offset < c.batchOffset {
		c.offsetChanged.Wait()
	}
	c.offsetChanged.L.Unlock()

	c.lock.RLock()
	return c.model, c.lock.RUnlock

}

type asyncProducer struct {
	producer sarama.AsyncProducer
	wg       *sync.WaitGroup
}

func (c *context) newAsyncProducer(f func(error)) (asyncProducer, error) {
	producer, err := sarama.NewAsyncProducerFromClient(c.client)
	if err != nil {
		return asyncProducer{}, fmt.Errorf("failed to create async producer: %v", err)
	}

	var wg sync.WaitGroup
	wg.Add(1)
	go func() {
		for err := range producer.Errors() {
			f(err)
		}
		wg.Done()
	}()
	wg.Add(1)
	go func() {
		for range producer.Successes() {
		}
		wg.Done()
	}()

	return asyncProducer{
		producer: producer,
		wg:       &wg,
	}, nil
}

func (p *asyncProducer) Close() {
	p.producer.AsyncClose()
	p.wg.Wait()
}

func (p asyncProducer) logChangeProductQuantity(msg *ChangeProductQuantity) error {

	topicMsg := &TopicMessage{
		Messages: &TopicMessage_ChangeProductQuantity{
			ChangeProductQuantity: msg,
		},
	}

	bytes, err := proto.Marshal(topicMsg)
	if err != nil {
		return fmt.Errorf("failed to serialize changeProductQuantity change massage: %v", err)
	}

	producerMsg := &sarama.ProducerMessage{
		Topic: Topic,
		Value: sarama.ByteEncoder(bytes),
	}
	p.producer.Input() <- producerMsg

	return nil
}

func (p asyncProducer) logStockCorrected(msg *StockCorrected) error {

	topicMsg := &TopicMessage{
		Messages: &TopicMessage_StockCorrected{
			StockCorrected: msg,
		},
	}

	bytes, err := proto.Marshal(topicMsg)
	if err != nil {
		return fmt.Errorf("failed to serialize stockCorrected change massage: %v", err)
	}

	producerMsg := &sarama.ProducerMessage{
		Topic: Topic,
		Value: sarama.ByteEncoder(bytes),
	}
	p.producer.Input() <- producerMsg

	return nil
}

func (p asyncProducer) logProduct(msg *Product) error {

	topicMsg := &TopicMessage{
		Messages: &TopicMessage_Product{
			Product: msg,
		},
	}

	bytes, err := proto.Marshal(topicMsg)
	if err != nil {
		return fmt.Errorf("failed to serialize product change massage: %v", err)
	}

	producerMsg := &sarama.ProducerMessage{
		Topic: Topic,
		Value: sarama.ByteEncoder(bytes),
	}
	p.producer.Input() <- producerMsg

	return nil
}

func (p asyncProducer) logOrderCart(msg *OrderCart) error {

	topicMsg := &TopicMessage{
		Messages: &TopicMessage_OrderCart{
			OrderCart: msg,
		},
	}

	bytes, err := proto.Marshal(topicMsg)
	if err != nil {
		return fmt.Errorf("failed to serialize orderCart change massage: %v", err)
	}

	producerMsg := &sarama.ProducerMessage{
		Topic: Topic,
		Value: sarama.ByteEncoder(bytes),
	}
	p.producer.Input() <- producerMsg

	return nil
}

type internalTopic struct {
	producer sarama.SyncProducer
}

func (c *internalTopic) logChangeProductQuantity(msg *ChangeProductQuantity) (int32, int64, error) {

	topicMsg := &TopicMessage{
		Messages: &TopicMessage_ChangeProductQuantity{
			ChangeProductQuantity: msg,
		},
	}

	bytes, err := proto.Marshal(topicMsg)
	if err != nil {
		return 0, 0, fmt.Errorf("failed to serialize changeProductQuantity change massage: %v", err)
	}

	producerMsg := &sarama.ProducerMessage{
		Topic: Topic,
		Value: sarama.ByteEncoder(bytes),
	}
	return c.producer.SendMessage(producerMsg)
}

func (c *internalTopic) logStockCorrected(msg *StockCorrected) (int32, int64, error) {

	topicMsg := &TopicMessage{
		Messages: &TopicMessage_StockCorrected{
			StockCorrected: msg,
		},
	}

	bytes, err := proto.Marshal(topicMsg)
	if err != nil {
		return 0, 0, fmt.Errorf("failed to serialize stockCorrected change massage: %v", err)
	}

	producerMsg := &sarama.ProducerMessage{
		Topic: Topic,
		Value: sarama.ByteEncoder(bytes),
	}
	return c.producer.SendMessage(producerMsg)
}

func (c *internalTopic) logProduct(msg *Product) (int32, int64, error) {

	topicMsg := &TopicMessage{
		Messages: &TopicMessage_Product{
			Product: msg,
		},
	}

	bytes, err := proto.Marshal(topicMsg)
	if err != nil {
		return 0, 0, fmt.Errorf("failed to serialize product change massage: %v", err)
	}

	producerMsg := &sarama.ProducerMessage{
		Topic: Topic,
		Value: sarama.ByteEncoder(bytes),
	}
	return c.producer.SendMessage(producerMsg)
}

func (c *internalTopic) logOrderCart(msg *OrderCart) (int32, int64, error) {

	topicMsg := &TopicMessage{
		Messages: &TopicMessage_OrderCart{
			OrderCart: msg,
		},
	}

	bytes, err := proto.Marshal(topicMsg)
	if err != nil {
		return 0, 0, fmt.Errorf("failed to serialize orderCart change massage: %v", err)
	}

	producerMsg := &sarama.ProducerMessage{
		Topic: Topic,
		Value: sarama.ByteEncoder(bytes),
	}
	return c.producer.SendMessage(producerMsg)
}

type publisher struct {
	producer sarama.SyncProducer
}

func (c *publisher) updateLoop(writes <-chan *sarama.ConsumerMessage) {
	for msg := range writes {

		cc := TopicMessage{}
		err := proto.Unmarshal(msg.Value, &cc)
		if err != nil {
			log.Fatalf("failed to unmarshal kafka massage %s/%d: %v", Topic, msg.Offset, err)
		}

		switch x := cc.GetMessages().(type) {

		case *TopicMessage_ChangeProductQuantity:
			err = c.publishChangeProductQuantity(msg.Offset, cc.GetChangeProductQuantity())
			if err != nil {
				panic(fmt.Errorf("failed to publish kafka massage %s/%d: %v", Topic, msg.Offset, err))
			}

		case *TopicMessage_StockCorrected:
			err = c.publishStockCorrected(msg.Offset, cc.GetStockCorrected())
			if err != nil {
				panic(fmt.Errorf("failed to publish kafka massage %s/%d: %v", Topic, msg.Offset, err))
			}

		case *TopicMessage_Product:
			err = c.publishProduct(msg.Offset, cc.GetProduct())
			if err != nil {
				panic(fmt.Errorf("failed to publish kafka massage %s/%d: %v", Topic, msg.Offset, err))
			}

		case *TopicMessage_OrderCart:
			err = c.publishOrderCart(msg.Offset, cc.GetOrderCart())
			if err != nil {
				panic(fmt.Errorf("failed to publish kafka massage %s/%d: %v", Topic, msg.Offset, err))
			}

		case nil:
			panic(fmt.Sprintf("context message is empty"))

		default:
			panic(fmt.Sprintf("unexpected type %T in oneof", x))
		}
	}
}

func (p *publisher) logOrderCreated(internalOffset int64, msg *public.OrderCreated) (int32, int64, error) {

	topicMsg := &public.TopicMessage{
		Messages: &public.TopicMessage_OrderCreated{
			OrderCreated: msg,
		},
	}

	bytes, err := proto.Marshal(topicMsg)
	if err != nil {
		return 0, 0, fmt.Errorf("failed to serialize orderCreated change massage: %v", err)
	}

	producerMsg := &sarama.ProducerMessage{
		Topic: public.Topic,
		Value: sarama.ByteEncoder(bytes),
	}
	return p.producer.SendMessage(producerMsg)
}
